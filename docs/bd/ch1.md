### **Chapter 1. A new paradigm for Big Data**

[p1-2]

Traditional systems, and the data management techniques associated with them, have failed to scale to Big Data.

To tackle the challenges of Big Data, a lof of new technologies has emerged, many of which have been grouped under the term *NoSQL*. In some ways, these new technologies are more complex than traditional databases, and in other ways they’re simpler. These systems can scale to vastly larger sets of data, but using these technologies effectively requires a fundamentally new set of techniques.  They aren’t one-size-fits-all solutions.

Many of these Big Data systems were pioneered by Google, including:

* Distributed filesystems,
* The  MapReduce computation framework,
* Distributed locking services.

Another notable pioneer in the space was Amazon, which created an innovative distributed key/value store called Dynamo. The open source community responded in the years following with Hadoop, HBase, MongoDB, Cassandra, RabbitMQ, and countless other projects.

This book is about complexity as much as it is about scalability. Some of the most basic ways people manage data in traditional systems like relational database management systems (RDBMSs) are too complex for Big Data systems.The simpler, alternative approach is the new paradigm for Big Data. This approach is dubbed the [**Lambda Architecture**](https://en.wikipedia.org/wiki/Lambda_architecture).

### How this book is structured

This book is theory book, focusing on how to approach building a solution to any Big Data problem. The book is structured into theory and illustration chapters.

### Scaling with a traditional database

#### Scaling with a queue

#### Scaling by sharding the database

#### Fault-tolerance issues begin

#### Corruption issues

#### What went wrong?
